# 版本历史

## v0.0

这是从`example/multitasking`的实验代码中产生的，当初本来想实现一个多线程+IO复用的简易web服务器，但没有想到比较好的应用场景（在我目前的理解中，多进程与多线程的主要区别在于内存隔离，所以当多个工作流需要有大量共享数据集时使用多线程才会有比较大的存储空间优势），而且《Linux高性能服务器》一书中的多线程代码结构不是很清晰，调试起来可能很麻烦，所以先考虑实现一版多进程+IO复用的简易web服务器，后续在此基础上压测debug、优化。

为了更直观地体会多进程和IO复用的优势，我用webbench短连接对v0.0的代码和`example/multitasking`中串行阻塞的代码做了测试对比。

### 1、基本架构

- epoll进行IO复用（包括统一信号源）
- 非阻塞IO+边缘触发
- 主进程水平触发监听socket+RR式通知子进程循环accept

### 2、相关文件描述符与作用

- IO复用文件描述符`epollfd_`
  - 需要复用监听socket、进程间通信、信号源管道
- 进程间通信文件描述符`fa_pipefd_[2]`
  - 父子进程共享同一个监听socket，主进程监听到socket有新连接到来时，为了防止惊群，以Round-Robin方式找到一个子进程，用管道通知该子进程，由子进程执行accept和后续的数据读写。
  - 需要设置成非阻塞，因为父进程水平触发时，往管道写数据的速率很快，很容易填满内核的管道缓冲，进而导致写阻塞。若子进程对IPC是边缘触发，且恰好在下一次进入epoll_wait前父进程已经阻塞，这会导致父子进程均阻塞，无法继续处理连接（见`example/multitasking/docs/多进程小记.md`中实验7的20220723的分析）
- 对外监听/接收连接的文件描述符`listenfd_`
  - 对该端口的监听须要在fork子进程前进行，以便父子进程共享该socket的文件描述符
  - 父进程使用水平触发（Level Trigger）。
    - 若使用边缘触发（Edge Trigger），在当前由子进程accept的模式下，并发量比较大时可能有问题（如处理速度跟不上导致全连接队列被填满，父进程已经ET触发往IPC管道写数据通知子进程，
  - 子进程在同一个监听端口上循环地accept。
    - 所以子进程需要非阻塞`listenfd_`
- 统一信号源`sig_pipefd[2]`
  - 因为信号处理函数需要往该文件描述符写数据，而sigaction似乎不支持特定命名空间下的信号处理函数，所以`sig_pipefd[2]`设置成了全局变量，待改进
  - 将SIGTERM、SIGINT、SIGCHLD的处理统一到IO复用
- 与连接后客户端通信的`client[].m_sockfd`：用于收发对客户端的数据
  - `client[].m_sockfd`在加入`m_epollfd`前需要设置为非阻塞
  - 需要处理非阻塞socket的EAGAIN（recv或write发现对非阻塞文件发生阻塞时，返回EAGAIN。详见`man recv`），用于跳出当前socket的处理循环。
  - 见`man epoll`的Example for suggested usage

### 3、测试结果

- 统一配置和测试命令

  - 配置：backlog为5、“多进程代码”中每个子进程最多循环100次accept

  - 测试命令

    ```shell
    # 服务端命令
    $ ./MainMultiProc 192.168.56.2 11111 > /dev/null
    $ ./test_block_http_handler 192.168.56.2 11111 > /dev/null
    # 客户端命令
    $ webbench -t 30 -c <并发量> http://192.168.56.2:11111/
    ```

- 测试1：单核Tom运行服务、单核Jerry运行webbench。

  | 测试程序\\并发量 | 1      | 2       | 5       | 10     | 20      | 50      |
  | ---------------- | ------ | ------- | ------- | ------ | ------- | ------- |
  | 串行代码         | 69,324 | 115,092 | 123,714 | 30,444 | 36,618  | 25,284  |
  | 多进程代码-1进程 | 57,846 | 78,360  | 98,400  | 97,386 | 84,024  | 85,140  |
  | 多进程代码-2进程 | 68,556 | 94,242  | 103,566 | 99,018 | 100,194 | 105,462 |

  | 测试程序\\并发量 | 100    | 200     | 500    | 1000    | 2000    | 2500    | 3000    |
  | ---------------- | ------ | ------- | ------ | ------- | ------- | ------- | ------- |
  | 串行代码         | 25,110 | 31,890  | 19,554 | 19,368  | 24,042  | 31,104  | 27,654  |
  | 多进程代码-1进程 | 97,662 | 96,924  | 93,600 | 92,520  | 94,212  | 92,124  | 91,548  |
  | 多进程代码-2进程 | 97,344 | 102,924 | 98,052 | 109,104 | 111,108 | 114,114 | 114,900 |

- 测试2：双核Tom运行服务、单核Jerry运行webbench。

  | 测试程序\\并发量 | 1      | 2       | 5       | 10      | 20      | 50      |
  | ---------------- | ------ | ------- | ------- | ------- | ------- | ------- |
  | 串行代码         | 90,296 | 113,718 | 129,270 | 38,316  | 28,572  | 36,162  |
  | 多进程代码-1进程 | 74,976 | 95,208  | 110,196 | 115,986 | 114,840 | 115,782 |
  | 多进程代码-2进程 | 78,432 | 106,104 | 126,342 | 121,092 | 119,988 | 114,978 |

  | 测试程序\\并发量 | 100     | 200     | 500     | 1000    | 2000    | 2500    | 3000    |
  | ---------------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |
  | 串行代码         | 35,412  | 21,174  | 22,320  | 29,970  | 18,864  | 25,248  | 32,082  |
  | 多进程代码-1进程 | 116,562 | 118,518 | 120,516 | 119,250 | 117,570 | 101,904 | 122,712 |
  | 多进程代码-2进程 | 112,992 | 114,798 | 122,196 | 135,732 | 157,794 | 179,292 | 171,720 |

- 简单分析：非阻塞式IO+epoll_wait事件处理（“多进程代码-1进程”）相比串行已经能抗住比较高的并发（如20220722分析中提到的，writev和close耗时更小，原因待探索）。**当前场景**（用`strace -c`分析，感觉writev、close和IPC的sendto应该是瓶颈，所以场景应该是IO密集型，CPU计算量少）下，多进程在单核机器上无明显性能优势（进程上下文切换可能耗时更多），多进程在多核+适当的进程数情况下似乎能体现优势。但多进程优势不明显，可能因为程序总体计算量不够（即IO和CPU可重叠的“计算”不多）。

#### 现象1：“串行代码”在并发量为10时，QPS有骤减

- 猜想1：writev和close开销增大。

  对比并发量为5和并发量为10时，`strace -c`耗时统计，可见accept的平均耗时相差不大（3us），writev和close的平均耗时则增加了20us。（详细信息可见`./example/multitasking/docs/多进程小记.md`）

  - 但为什么并发量上来了，writev和close花费的时间就多了？

- 猜想2：全连接队列溢出有影响

  通过`netstat -s | grep -i listen`可以知道，两份代码此时的连接队列是有溢出的，尝试增大backlog，“串行代码”（backlog为20）在并发量为10和20时的QPS接近“多进程代码”（backlog为5）在此场景下的表现，listen队列也没有溢出了。但从并发量为50开始，“串行代码”的QPS再次下滑。

#### 现象2：“串行代码”在QPS骤减前的并发量场景下，QPS与“多进程代码”接近

- 猜想1：当前场景下，程序瓶颈主要在writev和close这两个系统调用，可见两份代码在并发量为5和10时，writev和close的耗时差别不大，而且都是最高的。即瓶颈在写IO上。
  - 但网络带宽并没有跑满：通过`iftop`和`iperf`确认，局域网网卡上下行都有2000Mb/s，而`iftop`测试webbench上下行最高只有5Mb/s左右
- 猜想2：当前场景IO数据量太小，无法体现多进程优势。看`man 2 send`、`man 2 write`、`man 7 pipe`和`man 2 writev`，猜想因为**IO都是有缓冲区**的，write和writev的阻塞模式都类似管道的阻塞模式——触发阻塞条件是“是否向满载的写缓冲写数据”。本场景中程序响应只有66B，系统1个socket的tcp缓冲区最小是4096B（`/proc/sys/net/ipv4/tcp_wmen`）。正是因为IO数据量太小，所以不论有无设置阻塞socket，writrev都不会阻塞。
  - 影响writev系统调用时间的因素可能较多，还有很多疑惑

