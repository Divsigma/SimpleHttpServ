[TOC]

### 实验1-分析squid父进程和日志子进程之间的管道通信

#### 基本

- 使用`strace`、`ps`、`lsof`，观察启动时、启动后、通信时的管道系统调用
- **RTFM**。



#### 案例

```shell
# 1 查看进程基本关系
divsigma@tom:~/simple-server/examples/framework-intro$ ps -ef | grep squid
root       24982       1  0 00:39 ?        00:00:00 /usr/sbin/squid -sYC
proxy      24984   24982  0 00:39 ?        00:00:00 (squid-1) --kid squid-1 -sYC
proxy      24985   24984  0 00:39 ?        00:00:00 (logfile-daemon) /var/log/squid/access.log
divsigma   25708    5871  0 02:06 pts/2    00:00:00 grep --color=auto squid

# 2 启动telnet访问squid服务，并发送"hello"


# 3 telnet同时strace追踪日志守护进程
## 3.1 启动后，telnet squid服务，read(0,...的阻塞才会停止
divsigma@tom:~/simple-server/examples/framework-intro$ sudo strace -p 24985
strace: Process 24985 attached
read(0, "L1648951600.990      3 192.168.5"..., 4096) = 104
write(3, "1648951600.990      3 192.168.56"..., 101) = 101
## 3.2 用lsof进一步观察fd=0和fd=3是什么文件
### fd=0/1，被重定向到了同一个socket（怀疑是socketpair），而且0是读端
### fd=3，指向输出的日志文件，可以用vi打开，验证确实写入了上面的一行
divsigma@tom:~/simple-server/examples/framework-intro$ sudo lsof -p 24985
COMMAND     PID  USER   FD   TYPE             DEVICE SIZE/OFF   NODE NAME
log_file_ 24985 proxy    0u  unix 0xffff9e3aae889c00      0t0 178856 type=STREAM
log_file_ 24985 proxy    1u  unix 0xffff9e3aae889c00      0t0 178856 type=STREAM
log_file_ 24985 proxy    2u   CHR                1,3      0t0      6 /dev/null
log_file_ 24985 proxy    3w   REG              253,0      205 524295 /var/log/squid/access.log

# 4 telnet同时strace追踪主进程（日志进程的父进程）
divsigma@tom:~$ sudo strace -p 24984
strace: Process 24984 attached
epoll_wait(7, [], 65536, 790)       = 0
epoll_wait(7, [], 65536, 0)         = 0
epoll_wait(7, [{EPOLLIN, {u32=8, u64=8}}], 65536, 999) = 1
read(8, "hello\r\n", 4096)          = 7
getpid()                            = 24984
epoll_ctl(7, EPOLL_CTL_MOD, 8, {EPOLLIN|EPOLLOUT|EPOLLERR|EPOLLHUP, {u32=8, u64=8}}) = 0
epoll_wait(7, [{EPOLLOUT, {u32=8, u64=8}}], 65536, 273) = 1
write(8, "HTTP/1.1 400 Bad Request\r\nServer"..., 3673) = 3673
read(8, 0x7ffe9806b210, 65535)      = -1 EAGAIN (Resource temporarily unavailable)
epoll_ctl(7, EPOLL_CTL_ADD, 10, {EPOLLOUT|EPOLLERR|EPOLLHUP, {u32=10, u64=10}}) = 0
epoll_ctl(7, EPOLL_CTL_DEL, 8, 0x7ffe9807b484) = 0
close(8)                            = 0
epoll_wait(7, [{EPOLLOUT, {u32=10, u64=10}}], 65536, 269) = 1
write(10, "L1648951600.990      3 192.168.5"..., 104) = 104
epoll_wait(7, [{EPOLLOUT, {u32=10, u64=10}}], 65536, 266) = 1
epoll_ctl(7, EPOLL_CTL_DEL, 10, 0x7ffe9807b514) = 0
epoll_wait(7, [], 65536, 265)       = 0
epoll_wait(7, [], 65536, 0)         = 0
## 4.1 用lsof确认fd=7/8/10
### fd=7，是用于epoll_wait的fd；
### fd=10，根据DEVICE的地址和它在10上执行的write内容猜测
###        应该是用于跟子进程（日志进程）进行通信的socketpair写端（地址相差0x400）
### fd=9，不在lsof中，但观察strace输出，可见它是epoll_wait()返回的，而且从8中读取了“hello”，所以
###       8应该是进程用于和telnet通信的socket
divsigma@tom:~$ sudo lsof -p 24984
COMMAND   PID  USER   FD      TYPE             DEVICE SIZE/OFF   NODE NAME
squid   24984 proxy    0u      CHR                1,3      0t0      6 /dev/null
squid   24984 proxy    1u      CHR                1,3      0t0      6 /dev/null
squid   24984 proxy    2u      CHR                1,3      0t0      6 /dev/null
squid   24984 proxy    3u      REG              253,0     2603 524290 /var/log/squid/cache.log.1
squid   24984 proxy    4u      CHR                1,3      0t0      6 /dev/null
squid   24984 proxy    5u     IPv6             178853      0t0    UDP *:41812
squid   24984 proxy    6u     unix 0xffff9e3aae888000      0t0 178825 type=DGRAM
squid   24984 proxy    7u  a_inode               0,14        0  10376 [eventpoll]
squid   24984 proxy    9u     IPv4             178854      0t0    UDP *:59791
squid   24984 proxy   10u     unix 0xffff9e3aae889800      0t0 178855 type=STREAM
```





#### <span style="color:red">思考题</span>

##### Q1：直接`sudo strace service squid start`得到的输出为何找不到`fork`、`24984`和`24985`？如何跟踪squid启动过程中创建子进程和重定向时的系统调用？

描述：如题



#### Q2：`strace -p`实现的基本思路？

描述：系统调用会产生中断信号，strace捕获中断信号？







### 实验2-用POSIX接口共享内存demo

#### 基本

- 进程间通信（IPC）一般有四种方式：管道（常指双工管道）、信号量、消息队列、共享内存。
  - sockpair方式最原始简单，常用于父子进程通信（如实验1和之前的统一事件源）可以`man unix`查看更多（如实验3）
  - 后三种因为是由AT&T System V2版本的UNIX引入，所以统称为System V IPC。
  - <span style="color:red">各自优劣？</span>
- 共享内存针对**IPC**而言，有三种方式：mmap、SystemV的shm接口、POSIX的shm接口
  - <span style="color:red">三者使用方法？机制区别？优劣？</span>
- 可以尝试仿照实验1，用`lsof`和`ipcs`分析父子进程对mmap后文件的持有状态



#### 代码





#### <span style="color:red">思考题</span>

##### Q1：经典问题，线程vs进程？

描述：Linux2.6以前原生不支持线程，POSIX的线程库是怎么管理线程的（即NPTL）？相比进程模拟线程（如LinuxThread），有什么优缺点？

- https://labuladong.gitbook.io/algo-en/v.-common-knowledge/linuxprocess#:~:text=But%20both%20thread%20and%20process,shared%20with%20its%20parent%20process.
- https://www.informit.com/articles/article.aspx?p=370047&seqNum=3#:~:text=To%20the%20Linux%20kernel%2C%20there,certain%20resources%20with%20other%20processes.
- Linux2.6前不支持原生线程，LinuxThread中用`task_struct`管理线程，用clone系统调用并指定CLONE_THREAD创建线程，提供了管理线程，这相当于用进程模拟线程，有什么问题？
- 线程模型：完全用户调度（用户多线程对内核表现为单进程，内核用单线程调度该进程。早期Berkley UNIX采用该模式），完全内核调度（用户N线程映射为内核N线程。NPTL采用该模式），双层调度（N:M）。具体实现可用`getconf GNU_LIBPTHREAD_VERSION`查看。
- 









### 实验3-进程间传递文件描述符

#### 基本

- fd编号是局部的，为什么会有效？详见`man unix`的`SCM_RIGHTS`和`man open`的NOTES
  - 事实上，被传递的是文件描述（或者说文件对象）的引用，接收方会使用一个新的fd编号。文件描述（文件对象）记录了打开文件的各种信息，文件描述符是该对象的引用。
  - 还可以使用`kcmp()`的KCMP_FILE操作比较文件描述是否相等
    - 即可能有0==1！——`kcmp(pid_0, pid_1, KCMP_FILE, 0, 1)==0`
- 



#### 代码

- https://stackoverflow.com/questions/2358684/can-i-share-a-file-descriptor-to-another-process-on-linux-or-are-they-local-to-t



#### <span style="color:red">思考题</span>

##### Q1：关于文件描述符和设备的区别？为什么bash输入命令时看得见，输入password时看不见？如何实现？

描述：使用重定向似乎行不通

- 





### 实验4-子线程fork导致死锁

#### 基本

- 从`man fork`的NOTES中知道

  > Note the following further points:
  >
  > The  child **process is created with a single thread—the one that called fork()**.  The entire virtual address space of the parent is replicated in the child, including the **states of mutexes**, **condition variables, and other pthreads objects**; the use of pthread_atfork(3) may be  helpful  for  dealing with problems that this can cause.

  - 子进程只会从调用fork的线程上fork，所以**子进程是从父进程的main线程fork出来**的。因为**mutex是全局的**，子进程会继承mutex状态
  - 所以要让子进程的main线程进入死锁，就要在父进程的main线程fork之前，启动worker线程并获得锁（父进程在fork前先pthread_create并sleep一会儿），且未释放（worker获得锁后sleep，确保main线程fork时持有锁）。

- 最后状态

  - 子进程的main线程因为继承了父进程的worker线程中锁的状态，所以子进程的main线程死锁了。
  - 父进程的main线程因为wait(NULL)，也在等待
  - 父进程的worker线程不受影响。



#### 代码

- `multithread_fork.cc`

- 输出

  > divsigma@tom:~/simple-server/examples/multitasking$ ./multithread_fork
  > divsigma@tom:~/simple-server/examples/multitasking$ ./multithread_fork
  > [thread-140466592986880] trying to acquire lock
  > [thread-140466592986880] acquired lock
  > [main] waiting ...
  > [process-2780] trying to acquire lock
  > [thread-140466592986880] released lock
  >
  > NO RETURN

- 



#### <span style="color:red">思考题</span>

##### Q1：但`man fork`的DESCRIPTION又说子进程不会继承“process-associatd record locks”，mutex锁属于什么情况？

描述：如题。（为什么`man pthread_mutex_lock`也打不开？——POSIX手册在`manpages-posix-dev`包里）







### 实验5-用单一线程处理进程所有信号

#### 代码

- `signal_thread.cc`



#### <span style="color:red">思考题</span>

##### Q1：为什么`pthread_sigmask(SIG_BLOCK,...)`的信号能被`pthread_create`的线程`sigwait()`到？

描述：看不懂`man pthread_sigmask`的EXAMPLE。

- `man pthread_sigmask` --> `man sigprocmask` --> `man sigwait` --> `man sigwaitinfo`--> `man sigprocmask`--> `man sigwaitinfo`-->...

> **[man pthread_sigmask]**
>
> NOTES
>
> ​	A new thread inherits a copy of its creator's signal mask.
>
> 
>
> **[man sigprocmask]**
>
> SIG_BLOCK
>
> ​	The set of blocked signals is the union of the current set and the set argument.
>
> SIG_UNBLOCK
>               The signals in set are removed from the current set of blocked signals.  It is permissible to attempt to unblock a signal which is not blocked.
>
> ...
>
> NOTES
>
> ​	It is not possible to block SIGKILL or SIGSTOP.  Attempts to do so are silently ignored.
>
> ​	Each of the threads in a process has its own signal mask.
>
> ​	A child created via fork(2) inherits a copy of its parent's signal mask; the signal mask is preserved across execve(2).
>
> 
>
> **[man sigwaitinfo]**
>
> NOTES
>
> In normal usage, the calling program blocks the signals in set via a prior call to sigprocmask(2) (so that the default disposition for  these  signals does  not occur if they become pending between successive calls to sigwaitinfo() or sigtimedwait()) and does not establish handlers for these signals. 
>
> In a **multithreaded** program, the signal should be blocked in all threads, in order to prevent the signal being treated according to its default  disposition in a thread other than the one calling sigwaitinfo() or sigtimedwait()).
>
> The  set  of signals that is pending for a given thread is the union of the set of signals that is pending specifically for that thread and the set of signals that is pending for the process as a whole (see signal(7)).
>
> Attempts to wait for SIGKILL and SIGSTOP are silently ignored.
>
> If **multiple threads** of a process are blocked waiting for the same signal(s) in sigwaitinfo() or sigtimedwait(), then exactly one of the threads will actually receive the signal if it becomes pending for the process as a whole; which of the threads receives the signal is indeterminate.   

- 总之，细品`man`：
  - 每个线程都有自己的信号掩码，而且每个自己BLOCK的信号都有默认处理方式。`sigwait()`就是wait这些BLOCK的信号来**自定义处理**。所以多线程中为了统一BLOCK信号行为，应该先统一BLOCK（缺省各个线程的自定义处理），然后需要处理的线程调用`sigwait()`来处理。
  - 进程的每个线程都有信号掩码，并继承自创建它们的线程的信号掩码。通过`pthread_sigmask(SIG_BLOCK,...)`后的信号一般会调用`sigwait()`进行自定义处理，因为这些信号被掩盖后，默认没有处理函数（SIGKILL和SIGSTOP除外）。为了避免BLOCK的信号被`sigwait()`以外的线程默认处理了，一个进程的多个线程会同时BLOCK这些信号并默认不处理。最终最多只有一个调用了`sigwait()`的线程对BLOCK信号进行处理。



##### Q2：BLOCK==截获？如何查看信号默认处理的行为？





### 实验6-实现简单进程池

#### 基本

- 半同步/半异步反应堆模式：主进程监听m_listenfd，发现有连接请求后以Round-Robin方式找到一个子进程，用ipc_pipefd通知它，子进程`accept()`连接并进行非阻塞的读取和处理。
- 主进程关键文件描述符
  - IO复用文件描述符`m_epollfd`：其interest list包含`m_listenfd`、`ipc_pipefd[2]`和`sig_pipefd[2]`。
    - 需要处理信号到达时的EINTR（epoll_wait会阻塞，信号到达时先EINTR返回一次再返回`sig_pipefd[2]`）
  - 对外监听连接`m_listenfd`：
  - 进程间通信`ipc_pipefd[2]`：使用socketpair。仅用于通知子进程有新连接到达，但本实验代码中不传递`m_listenfd`。
  - 统一信号源`sig_pipefd[2]`：使用socketpair。将SIGTERM、SIGINT、SIGCHLD的处理统一到IO复用。
- 子进程关键文件描述符
  - IO复用文件描述符`m_epollfd`：其interest list包含`client[].m_sockfd`、`ipc_pipefd[2]`和`sig_pipefd[2]`。
    - `client[].m_sockfd`在加入`m_epollfd`前需要设置为非阻塞
  - 接受对外连接的`m_listenfd`：用于accept()得到`client_sockfd`，**从主进程dup/fork获取**。
  - 与连接后客户端通信的`client[].m_sockfd`：用于收发对客户端的数据
    - `client[].m_sockfd`在加入`m_epollfd`前需要设置为非阻塞
    - 需要处理非阻塞socket的EAGAIN（recv或write发现对非阻塞文件发生阻塞时，返回EAGAIN。详见`man recv`），用于跳出当前socket的处理循环。
    - **见`man epoll`的Example for suggested usage**
  - 进程间通信`ipc_pipefd[2]`：使用socketpair。仅用于接收主进程的通知。
  - 统一信号源`sig_pipefd[2]`：同主进程。



#### 代码

- `processpool.h`
- `test_processpool.cc`



#### <span style="color:red">思考题</span>

##### Q1：`listen()`、`accept()`、`recv()`、`write()`、`epoll_wait()`的阻塞行为是？

- 阻塞：accept、epoll_wait
- 不阻塞：listen
- 阻塞/不阻塞：recv、write（不阻塞时处理两个errno：EAGAIN或EWOULDBLOCK）



##### Q2：为什么socketpair没有O_NONBLOCK标志（用fcntl(fd, F_GETFL)获取），统一到IO后其send和recv看起来没有阻塞？



### 实验7-对比多进程和串行的http处理代码效率（注意workload和稳定复现）


#### 基本

- 多进程代码：
  - `processpool.h`
  - `nonblock_http_handler.h`
  - `test_multiproc_http_handler.cc`
- 串行代码
  - `test_block_http_handler.cc`



#### 问题1（20220718）

描述：为什么多进程代码（开5个处理进程）在VPS上`webbench -c 500`时会卡住（log不再更新）？串行代码则不会？

1、尝试在虚拟机Tom复现，不出现问题。



#### 问题2（20220718）：多进程代码无法连续工作

描述：为什么”多进程代码-1进程“在虚拟机Tom下连续多次`webbench -t 10 -c 2`时可能会卡住（无法继续处理），此时输出的log多表现为某处理进程在epoll_wait处阻塞。

- 20220718：最简稳定复现的情况

  ```shell
  # 情况1：第一次webbench后无法继续webbench
  ## 1子进程，backlog=5,
  (bash0)$ ./test_multiproc_http_handler 192.168.56.2 11111
  ## 第一次webbench
  (bash1)$ webbench -t 1 -c 2 http://192.168.56.2:11111/
  speed=1+pages/min
  ## 第一次webbench返回后，第二次webbench的QPS=0
  (bash1)$ webbench -t 1 -c 2 http://192.168.56.2:11111/
  speed=0pages/min
  
  # 情况2：第一次webbench后无法wget
  ## 1子进程，backlog=5,
  (bash0)$ ./test_multiproc_http_handler 192.168.56.2 11111
  ## 第一次webbench
  (bash1)$ webbench -t 1 -c 2 http://192.168.56.2:11111/
  speed=1+pages/min
  ## 第一次webbench后，wget一直在等待回复
  (bash1)$ wget http://192.168.56.2:11111/
  Request sent, waiting for Respond ...
  ## 观察1：对于情况2，wget之后bash0输出一个报文内容是“...Webbench 1.15...”的处理结果，此时运行下述命令，bash1输出一个报文内容是“...Wget...”的处理结果，而且bash1成功wget
  ## bash2承接bash1后的wget后再发起一次wget，此时bash1成功wget
  (bash2)$ wget http://192.168.56.2:11111/
  Request sent, waiting for Respond ...
  ```

- 分析工具

  - `tcpdump`抓包
  - `strace -f -e trace=network -tt`跟踪网络相关的系统调用（用于对应tcpdump包的结果）
  - `netstat -nat`查看第一次webbench后是否有异常链接（如CLOSE_WAIT）

- 抓包分析：`./log/202207201501-tcpdump`日志分析
  
  - 产生日志的命令
    
    ```shell
    $ sudo tcpdump -ntXi lo port 11111 > tcpdump_log # 输出到控制台的tcpdump好像不全？
    ```
    
  - 首先完成了一次试探性的报文（端口40336），端口40338先完成三次握手、传输请求报文、收到确认，接着端口40340完成三次握手、传输请求、收到确认，随后端口40338才收到回复、四次挥手。可见建立连接的端口n，在端口n+2建立连接并传输请求报文后，才收到回复并关闭链接。
  - 如果持续下去，在第二次webbench时，试探性报文用于触发处理上次webbench遗留的最后一个连接的响应，第二次webbench并发发起的两个连接则无法被触发处理。可能跟epoll_wait的触发机制有关。
  
- 系统调用分析：`./log/202207201501-strace`日志分析
  
  - 产生日志的命令
    
    ```shell
    $ sudo strace -f -e trace=network -s 1000 -tt \
    ./test_multiproc_http_handler 192.168.56.2 11111
    ```
    
  - 陆续的send(5)，recv(4)，accept，recv(8)，结合accept队列情况和`lsof`查看的文件描述符情况，可知道每次父进程跳出epoll_wait后调用send(5)通知子进程，子进程收到信号跳出epoll_wait执行recv(4)，然后accept一次，同时recv(8)读取TCP内核缓存中的数据，完成响应。
  
  - 将系统调用时序和抓包时序对应，发现
    - 子进程中的accept()依赖于父进程的send(5)，
    - webbench最开始的2个连接并发建立，请求报文传输完毕后，进入listen的backlog队列，仅触发1次父进程的sys_exit_epoll_wait（待straceepoll确定，但只触发了一次send(5)），从而只触发了子进程的1次accpet。
    - 所以`webbench -t 1 -c 2`的最后，会有一个建立连接并确认了请求报文的端口，但没有被accept。
  - 关于未accept能否建立TCP：https://cloud.tencent.com/developer/article/1891404
  - 关于TCP的send和recv机制（未调用recv时报文能否收到ACK）：https://www.ccppcoding.com/archives/173
  - 关于ET/LT、阻塞/非阻塞的accept
    - https://mp.weixin.qq.com/s/nacUx_qQr93_y-CsVxkejA
    - https://www.cnblogs.com/kex1n/p/7211175.html
  
- 解决方案1
  - 原代码中，listenfd非阻塞，父进程epoll边缘触发监听listenfd，触发后用socketpair通知子进程，子进程做1次accept()。这会导致并发进入backlog队列的多个短连接（三次握手后立刻传送了请求报文）只被触发1次accept()。
  - 改进：边缘触发的listenfd需要非阻塞式listenfd+循环accept



#### 问题3（20220718）：2个客户端并发时，多进程程序的QPS比串行程序的还小

描述：为什么“多进程代码-2进程”在虚拟机Tom下`webbench -t 10 -c 2`的QPS比串行的还小？
- 20220718：测试
  
  - 虚拟机Tom启动服务，虚拟机Tom作webbench
  - 串行代码连续测试3次，平均为在61,000pages/min。
  - 2进程代码连续测试3次，第一次51,000pages/min，第二第三次0pages/min。
  
- 20220720：测试
  - 虚拟机Tom启动服务，输出定向到/dev/null，虚拟机Tom作webbench
  - 串行代码：连续测试3次，平均为770,000pages/min
  - 多进程代码-1进程：连续测试3次，平均为533,000pages/min
  - 多进程代码-2进程：连续测试3次，平均为510,000pages/min
  - 多进程代码-4进程：连续测试3次，平均为447,000pages/min
  
- 分析工具

  - `strace -f -tt -e trace=network`
  - `netstat -s |grep -i listen`：采样监测listen队列溢出总数
  - `sudo ss -tlp`：采样监测listen队列实时容量
  - `sudo netstat -natp | grep <port>`：采样监测特定端口ESTABLISHED连接和进程绑定情况（只能看到自己创建的进程）

- `./log/202207210940-strace`日志分析

  - 配置：多进程代码-2进程、backlog为5、每个子进程最多循环100次accept、父进程监听`192.168.56.2:11111`

  - 产生日志的命令

    ```shell
    $ sudo strace -f -tt -s 1000 -e trace=network,epoll_wait,writev -o strace.out \
    ./test_multiproc_http_handler 192.168.56.2 11111
    ```

  - 多数时候，2个子进程交替串行地处理2个客户端的串行请求。因当前场景下，webbench每个客户端都是串行地发送请求，所以一个子进程writev后，才触发CPU调度父进程跳出epoll_wait，然后父进程Round-Robin式通知下一个子进程接收处理。当前场景下，webbench各个客户端串行发送短连接，而程序对短连接的处理时间≈新连接ESTABLISH的时间（即backlog多数时候未被填满），此时引入多进程，相当于串行基础上引入了更多epoll_wait和IPC。

  - 可以用多个命令确定backlog状态：https://juejin.cn/post/6844903949221232647

    - 方法1：用`netstat -s`多次采样，观察backlog队列溢出情况

      ```shell
      ## 启动服务程序
      (bash0)$ ./test_block_http_handler 192.168.56.2 -p 11111
      ## 启动客户程序，2客户端并发
      (bash1)$ webbench -t 60 -c 2 http://192.168.56.2:11111/
      ## 采样监测，可见此时listen queue的溢出数量稳定
      (bash2)$ sudo netstat -s | grep -i listen
          113132 times the listen queue of a socket overflowed
          113132 SYNs to LISTEN sockets dropped
      (bash2)$ sudo netstat -s | grep -i listen
          113132 times the listen queue of a socket overflowed
          113132 SYNs to LISTEN sockets dropped
      (bash2)$ sudo netstat -s | grep -i listen
          113132 times the listen queue of a socket overflowed
          113132 SYNs to LISTEN sockets dropped
      ## 启动客户程序，100客户端并发
      (bash1)$ webbench -t 60 -c 100 http://192.168.56.2:11111/
      ## 采样监测，可见此时listen queue的溢出数量持续增加
      (bash2)$ sudo netstat -natps | grep -i listen
          115887 times the listen queue of a socket overflowed
          115887 SYNs to LISTEN sockets dropped
      (bash2)$ sudo netstat -natps | grep -i listen
          115926 times the listen queue of a socket overflowed
          115926 SYNs to LISTEN sockets dropped
      (bash2)$ sudo netstat -natps | grep -i listen
          115952 times the listen queue of a socket overflowed
          115952 SYNs to LISTEN sockets dropped
      ```

    - 方法2：用`sudo ss -tlp`多次采样，直接查看backlog状态（`netstat`似乎做不到？`-p`选项不会列出不属于用户的进程，详见`man netstat`和`man ss`），处于监听状态的socket的Send-Q为backlog参数，Recv-Q为backlog队列中ESTABLISH数量。内核实际的backlog队列大小为“backlog参数+1”

      ```shell
      ## 启动服务程序
      (bash0)$ ./test_block_http_handler 192.168.56.2 -p 11111
      ## 启动客户程序，2客户端并发
      (bash1)$ webbench -t 60 -c 2 http://192.168.56.2:11111/
      ## 采样监测，可见Send-Q稳定地大于Recv-Q
      (bash2)$ sudo ss -tlp
      LISTEN  1  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=103834,fd=3))
      (bash2)$ sudo ss -tlp
      LISTEN  1  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=103834,fd=3))
      (bash2)$ sudo ss -tlp
      LISTEN  1  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=103834,fd=3))
      ## 启动客户程序，100客户端并发
      (bash1)$ webbench -t 60 -c 100 http://192.168.56.2:11111/
      ## 采样监测，可见Send-Q ≤ Recv-Q，listen queue可能溢出了
      (bash2)$ sudo ss -tlp
      LISTEN  6  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=108200,fd=3))
      (bash2)$ sudo ss -tlp
      LISTEN  5  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=108200,fd=3))
      (bash2)$ sudo ss -tlp
      LISTEN  5  5  192.168.56.2:11111  0.0.0.0:*  users:(("test_block_http",pid=108200,fd=3))
      ```

    - 方法3：用`sudo netstat -natp | grep ESTABLISH`采样监测完成三次握手的连接和进程的绑定情况（有一些难以理解的情况。。。）

      ```shell
      ## 启动服务程序
      (bash0)$ ./test_block_http_handler 192.168.56.2 -p 11111
      ## 启动客户程序，2客户端并发
      (bash1)$ webbench -t 60 -c 2 http://192.168.56.2:11111/
      ## 第一次查看，存在客户端对服务端的单向ESTABLISHED
      (bash2)$ sudo netstat -natp | sudo grep ESTABLISH
      tcp    0      0 192.168.56.2:22         192.168.56.1:7942       ESTABLISHED 96894/sshd: divsigm 
      tcp    0      0 127.0.0.1:33021         127.0.0.1:51988         ESTABLISHED 97072/node
      ...
      tcp    0      0 192.168.56.2:57402      192.168.56.2:11111      ESTABLISHED -
      tcp    0      0 192.168.56.2:22         192.168.56.1:5565       ESTABLISHED 87225/sshd: divsigm
      tcp    0      0 192.168.56.2:57580      192.168.56.2:11111      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:57608      192.168.56.2:11111      ESTABLISHED -
      ## 第二次查看，存在服务端对客户端的单向ESTABLISHED
      (bash2)$ sudo netstat -natp | grep ESTABLISH
      tcp    0      0 192.168.56.2:41600      192.168.56.2:11111      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:41630      192.168.56.2:11111      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:41734      192.168.56.2:11111      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:11111      192.168.56.2:41810      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:22         192.168.56.1:7942       ESTABLISHED 96894/sshd: divsigm 
      tcp    0      0 192.168.56.2:41828      192.168.56.2:11111      ESTABLISHED -                   
      tcp    0      0 192.168.56.2:11111      192.168.56.2:41826      ESTABLISHED -
      tcp    0      0 127.0.0.1:51988         127.0.0.1:33021         ESTABLISHED 97019/sshd: divsigm 
      tcp    0     45 127.0.0.1:33021         127.0.0.1:51986         ESTABLISHED 1139/node
      tcp    0      0 192.168.56.2:41904      192.168.56.2:11111      ESTABLISHED -
      ...
      tcp    0      0 192.168.56.2:11111      192.168.56.2:41902      ESTABLISHED -
      ## 第三次查看，存在双向ESTABLISHED，但Send-Q有的是64（抓包可知，当前webbench请求报文长度为64），有的是0
      (bash2)$ sudo netstat -natp | grep ESTABLISH
      tcp    0      0 192.168.56.2:49734      192.168.56.2:11111      ESTABLISHED -                   
      ...
      tcp   64      0 192.168.56.2:11111      192.168.56.2:49734      ESTABLISHED - 
      tcp    0      0 192.168.56.2:53450      192.168.56.2:11111      ESTABLISHED -
      ...
      tcp    0      0 192.168.56.2:11111      192.168.56.2:53450      ESTABLISHED -
      ```



#### 问题4（20220721）：





### 实验8-线程池和进程池相关

（待学习Cpp Primer过程中同步补充）

